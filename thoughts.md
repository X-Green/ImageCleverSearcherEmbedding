基本原理：使用embedding model例如Siglip2或者DinoV2将文本或图像转换为向量表示。然后，使用向量数据库（如Pinecone、Weaviate或FAISS）存储和索引这些向量，以便高效地进行相似性搜索和检索。
自动扫描电脑中图像文件，空闲时间进行处理，生成图像的embedding并存储在向量数据库中。
当用户查询时，系统会生成其embedding，并在向量数据库中进行相似性搜索，找到最相关的存储项。然后，系统可以基于这些相关项生成回答或推荐内容。

基本架构：
1. 模型服务端：部署embedding模型的API服务，负责将输入文本或图像转换为向量表示。尽量放在本地以减少延迟、保护隐私。需要考虑模型的计算资源需求。需要适配不同硬件环境（CUDA XPU NPU CPU）。
2. 向量服务端：选择合适的向量数据库（如Pinecone、Weaviate或FAISS）来存储和索引生成的向量。需要考虑数据库的扩展性、查询速度和成本。也是部署在本地
3. 客户端应用：
- 图像扫描器：定期扫描电脑中的图像文件，调用模型服务端生成embedding，并将结果存储在向量服务端。
- 查询接口：允许用户输入查询（文本或图像），调用模型服务端生成查询的embedding，并在向量服务端进行相似性搜索，返回相关结果。
